{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Heart Disease Prediction Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, recall_score\n",
    "import joblib\n",
    "import pymongo\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv('../backend/.env')\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (920, 16)\n",
      "Columns: ['id', 'age', 'sex', 'dataset', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalch', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num']\n",
      "Target counts:\n",
      "num\n",
      "0    411\n",
      "1    265\n",
      "2    109\n",
      "3    107\n",
      "4     28\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
       "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
       "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
       "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
       "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
       "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
       "\n",
       "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
       "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
       "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
       "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
       "3          normal   187.0  False      3.5  downsloping  0.0   \n",
       "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
       "\n",
       "                thal  num  \n",
       "0       fixed defect    0  \n",
       "1             normal    2  \n",
       "2  reversable defect    1  \n",
       "3             normal    0  \n",
       "4             normal    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/raw/heart_disease_uci.csv')\n",
    "print(f\"Shape: {data.shape}\")\n",
    "print(\"Columns:\", data.columns.tolist())\n",
    "print(f\"Target counts:\\n{data['num'].value_counts()}\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        920 non-null    int64  \n",
      " 1   age       920 non-null    int64  \n",
      " 2   sex       920 non-null    object \n",
      " 3   dataset   920 non-null    object \n",
      " 4   cp        920 non-null    object \n",
      " 5   trestbps  861 non-null    float64\n",
      " 6   chol      890 non-null    float64\n",
      " 7   fbs       830 non-null    object \n",
      " 8   restecg   918 non-null    object \n",
      " 9   thalch    865 non-null    float64\n",
      " 10  exang     865 non-null    object \n",
      " 11  oldpeak   858 non-null    float64\n",
      " 12  slope     611 non-null    object \n",
      " 13  ca        309 non-null    float64\n",
      " 14  thal      434 non-null    object \n",
      " 15  num       920 non-null    int64  \n",
      "dtypes: float64(5), int64(3), object(8)\n",
      "memory usage: 115.1+ KB\n",
      "None\n",
      "\n",
      "Missing values:\n",
      "id            0\n",
      "age           0\n",
      "sex           0\n",
      "dataset       0\n",
      "cp            0\n",
      "trestbps     59\n",
      "chol         30\n",
      "fbs          90\n",
      "restecg       2\n",
      "thalch       55\n",
      "exang        55\n",
      "oldpeak      62\n",
      "slope       309\n",
      "ca          611\n",
      "thal        486\n",
      "num           0\n",
      "dtype: int64\n",
      "\n",
      "Basic stats:\n",
      "               id         age    trestbps        chol      thalch     oldpeak  \\\n",
      "count  920.000000  920.000000  861.000000  890.000000  865.000000  858.000000   \n",
      "mean   460.500000   53.510870  132.132404  199.130337  137.545665    0.878788   \n",
      "std    265.725422    9.424685   19.066070  110.780810   25.926276    1.091226   \n",
      "min      1.000000   28.000000    0.000000    0.000000   60.000000   -2.600000   \n",
      "25%    230.750000   47.000000  120.000000  175.000000  120.000000    0.000000   \n",
      "50%    460.500000   54.000000  130.000000  223.000000  140.000000    0.500000   \n",
      "75%    690.250000   60.000000  140.000000  268.000000  157.000000    1.500000   \n",
      "max    920.000000   77.000000  200.000000  603.000000  202.000000    6.200000   \n",
      "\n",
      "               ca         num  \n",
      "count  309.000000  920.000000  \n",
      "mean     0.676375    0.995652  \n",
      "std      0.935653    1.142693  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    0.000000  \n",
      "50%      0.000000    1.000000  \n",
      "75%      1.000000    2.000000  \n",
      "max      3.000000    4.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"Data info:\")\n",
    "print(data.info())\n",
    "print(\"\\nMissing values:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"\\nBasic stats:\")\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning: (299, 14)\n",
      "After feature engineering: (299, 20)\n",
      "Target distribution: target\n",
      "0    160\n",
      "1    139\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def clean_and_prep(df):\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    new_df = new_df.rename(columns={'num': 'target'})\n",
    "    \n",
    "    new_df['sex'] = new_df['sex'].map({'Male': 1, 'Female': 0})\n",
    "    \n",
    "    cp_map = {'typical angina': 0, 'atypical angina': 1, 'non-anginal': 2, 'asymptomatic': 3}\n",
    "    new_df['cp'] = new_df['cp'].map(cp_map)\n",
    "    \n",
    "    new_df['fbs'] = new_df['fbs'].map({True: 1, False: 0})\n",
    "    new_df['exang'] = new_df['exang'].map({True: 1, False: 0})\n",
    "    \n",
    "    restecg_map = {'normal': 0, 'st-t abnormality': 1, 'lv hypertrophy': 2}\n",
    "    new_df['restecg'] = new_df['restecg'].map(restecg_map)\n",
    "    \n",
    "    slope_map = {'upsloping': 0, 'flat': 1, 'downsloping': 2}\n",
    "    new_df['slope'] = new_df['slope'].map(slope_map)\n",
    "    \n",
    "    thal_map = {'normal': 1, 'fixed defect': 2, 'reversable defect': 3}\n",
    "    new_df['thal'] = new_df['thal'].map(thal_map)\n",
    "    \n",
    "    if 'thalch' in new_df.columns and 'thalach' not in new_df.columns:\n",
    "        new_df['thalach'] = new_df['thalch']\n",
    "    \n",
    "    new_df['target'] = (new_df['target'] > 0).astype(int)\n",
    "    \n",
    "    cols = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', \n",
    "            'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "    new_df = new_df[cols].dropna()\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def make_features(df):\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    new_df['chol_ratio'] = new_df['chol'] / new_df['age']\n",
    "    new_df['hr_ratio'] = new_df['thalach'] / new_df['age']\n",
    "    new_df['oldpeak_ratio'] = new_df['oldpeak'] / new_df['age']\n",
    "    \n",
    "    new_df['cp_hr'] = new_df['cp'] * new_df['thalach']\n",
    "    new_df['sex_age'] = new_df['sex'] * new_df['age']\n",
    "    \n",
    "    new_df['age_bin'] = pd.cut(new_df['age'], bins=[0, 40, 55, 70, 100], \n",
    "                               labels=['young', 'middle', 'senior', 'old'])\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "clean_data = clean_and_prep(data)\n",
    "print(f\"After cleaning: {clean_data.shape}\")\n",
    "\n",
    "clean_data = make_features(clean_data)\n",
    "print(f\"After feature engineering: {clean_data.shape}\")\n",
    "print(f\"Target distribution: {clean_data['target'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical: ['age_bin']\n",
      "Numerical: ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'chol_ratio', 'hr_ratio', 'oldpeak_ratio', 'cp_hr', 'sex_age']\n",
      "Train: (239, 19), Test: (60, 19)\n"
     ]
    }
   ],
   "source": [
    "X = clean_data.drop('target', axis=1)\n",
    "y = clean_data['target']\n",
    "\n",
    "cat_features = ['age_bin']\n",
    "num_features = [col for col in X.columns if col not in cat_features]\n",
    "\n",
    "print(f\"Categorical: {cat_features}\")\n",
    "print(f\"Numerical: {num_features}\")\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42, stratify=y)\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training lr...\n",
      "AUC: 0.9330\n",
      "Recall: 0.7857\n",
      "Best params: {'model__C': 1, 'model__penalty': 'l2'}\n",
      "\n",
      "Training rf...\n",
      "AUC: 0.9163\n",
      "Recall: 0.6786\n",
      "Best params: {'model__max_depth': 5, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "\n",
      "Training xgb...\n",
      "AUC: 0.9062\n",
      "Recall: 0.6429\n",
      "Best params: {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__n_estimators': 200}\n",
      "\n",
      "Best: lr with AUC: 0.9330\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'lr': {\n",
    "        'model': LogisticRegression(random_state=42),\n",
    "        'params': {\n",
    "            'model__C': [0.1, 1, 10],\n",
    "            'model__penalty': ['l2']\n",
    "        }\n",
    "    },\n",
    "    'rf': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'model__n_estimators': [100, 200],\n",
    "            'model__max_depth': [5, 10, None],\n",
    "            'model__min_samples_split': [2, 5]\n",
    "        }\n",
    "    },\n",
    "    'xgb': {\n",
    "        'model': XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "        'params': {\n",
    "            'model__n_estimators': [100, 200],\n",
    "            'model__max_depth': [3, 5, 7],\n",
    "            'model__learning_rate': [0.01, 0.1]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_score = 0\n",
    "best_name = \"\"\n",
    "results = {}\n",
    "\n",
    "for name, config in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('prep', prep),\n",
    "        ('model', config['model'])\n",
    "    ])\n",
    "    \n",
    "    search = GridSearchCV(pipe, config['params'], cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    pred = search.predict(X_test)\n",
    "    pred_prob = search.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    auc = roc_auc_score(y_test, pred_prob)\n",
    "    rec = recall_score(y_test, pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': search.best_estimator_,\n",
    "        'auc': auc,\n",
    "        'recall': rec,\n",
    "        'params': search.best_params_\n",
    "    }\n",
    "    \n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"Best params: {search.best_params_}\")\n",
    "    \n",
    "    if auc > best_score:\n",
    "        best_score = auc\n",
    "        best_model = search.best_estimator_\n",
    "        best_name = name\n",
    "\n",
    "print(f\"\\nBest: {best_name} with AUC: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lr model to model.joblib\n",
      "\n",
      "All results:\n",
      "lr: AUC=0.9330, Recall=0.7857\n",
      "rf: AUC=0.9163, Recall=0.6786\n",
      "xgb: AUC=0.9062, Recall=0.6429\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(best_model, '../model.joblib')\n",
    "print(f\"Saved {best_name} model to model.joblib\")\n",
    "\n",
    "print(\"\\nAll results:\")\n",
    "for name, res in results.items():\n",
    "    print(f\"{name}: AUC={res['auc']:.4f}, Recall={res['recall']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save to Database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 299 records to patients\n"
     ]
    }
   ],
   "source": [
    "def save_data(df, collection='patients'):\n",
    "    try:\n",
    "        uri = os.getenv('MONGO_URI')\n",
    "        if not uri:\n",
    "            print(\"No MONGO_URI found\")\n",
    "            return\n",
    "        \n",
    "        client = pymongo.MongoClient(uri)\n",
    "        db = client.heart_disease_db\n",
    "        coll = db[collection]\n",
    "        \n",
    "        coll.delete_many({})\n",
    "        \n",
    "        records = df.to_dict('records')\n",
    "        for rec in records:\n",
    "            rec['created_at'] = datetime.utcnow()\n",
    "            rec['source'] = 'notebook'\n",
    "        \n",
    "        result = coll.insert_many(records)\n",
    "        print(f\"Saved {len(result.inserted_ids)} records to {collection}\")\n",
    "        \n",
    "        coll.create_index([('created_at', -1)])\n",
    "        client.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "\n",
    "save_data(clean_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 features:\n",
      "                feature  importance\n",
      "19  cat__age_bin_senior    1.313660\n",
      "11              num__ca    1.062286\n",
      "12            num__thal    0.781825\n",
      "0              num__age    0.662419\n",
      "14        num__hr_ratio    0.483439\n",
      "3         num__trestbps    0.481944\n",
      "20   cat__age_bin_young    0.467620\n",
      "1              num__sex    0.444718\n",
      "6          num__restecg    0.442851\n",
      "15   num__oldpeak_ratio    0.394705\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def get_importance(model, feature_names):\n",
    "    try:\n",
    "        if hasattr(model.named_steps['model'], 'feature_importances_'):\n",
    "            imp = model.named_steps['model'].feature_importances_\n",
    "        elif hasattr(model.named_steps['model'], 'coef_'):\n",
    "            imp = np.abs(model.named_steps['model'].coef_[0])\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        names = model.named_steps['prep'].get_feature_names_out()\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'feature': names,\n",
    "            'importance': imp\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "importance = get_importance(best_model, X.columns)\n",
    "if importance is not None:\n",
    "    print(\"\\nTop 10 features:\")\n",
    "    print(importance.head(10))\n",
    "else:\n",
    "    print(\"Could not get feature importance\")\n",
    "\n",
    "print(\"\\nDone!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
